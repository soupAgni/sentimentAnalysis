{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.util import ngrams\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "elon = pd.read_csv('elon_data.csv',parse_dates=[0], infer_datetime_format=True)\n",
    "elon = elon.drop(['Unnamed: 0'], axis=1)\n",
    "elon = elon.dropna(axis=0)\n",
    "bored_elon = pd.read_csv('bored_elon_data.csv',parse_dates=[0], infer_datetime_format=True)\n",
    "bored_elon = bored_elon.drop(['Unnamed: 0'], axis=1)\n",
    "bored_elon = elon.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Date</th>\n",
       "      <th>Retweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@RanNatanzon @Tesla @Cortica This is completel...</td>\n",
       "      <td>Tue Mar 20 18:47:20 +0000 2018</td>\n",
       "      <td>195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Paid respects to Masada earlier today. Live fr...</td>\n",
       "      <td>Tue Mar 20 02:20:29 +0000 2018</td>\n",
       "      <td>844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Learning how to pour flaming absinthe over a t...</td>\n",
       "      <td>Mon Mar 19 18:09:26 +0000 2018</td>\n",
       "      <td>970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@IraEhrenpreis @Tesla Thanks for your support ...</td>\n",
       "      <td>Sun Mar 18 04:31:53 +0000 2018</td>\n",
       "      <td>157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@TheOnion Your cruel taunts cut me deep. Deep....</td>\n",
       "      <td>Thu Mar 15 18:46:45 +0000 2018</td>\n",
       "      <td>465</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet  \\\n",
       "0  @RanNatanzon @Tesla @Cortica This is completel...   \n",
       "1  Paid respects to Masada earlier today. Live fr...   \n",
       "2  Learning how to pour flaming absinthe over a t...   \n",
       "3  @IraEhrenpreis @Tesla Thanks for your support ...   \n",
       "4  @TheOnion Your cruel taunts cut me deep. Deep....   \n",
       "\n",
       "                             Date Retweets  \n",
       "0  Tue Mar 20 18:47:20 +0000 2018      195  \n",
       "1  Tue Mar 20 02:20:29 +0000 2018      844  \n",
       "2  Mon Mar 19 18:09:26 +0000 2018      970  \n",
       "3  Sun Mar 18 04:31:53 +0000 2018      157  \n",
       "4  Thu Mar 15 18:46:45 +0000 2018      465  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bored_elon.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#remove punctuation from Tweet text\n",
    "elon['Tweet'] = elon['Tweet'].str.replace('[^\\w\\s]','')\n",
    "bored_elon['Tweet'] = bored_elon['Tweet'].str.replace('[^\\w\\s]','')\n",
    "\n",
    "#add in label columns for data\n",
    "elon['Label'] = \"Elon\"\n",
    "bored_elon['Label'] = \"BoredElon\"\n",
    "\n",
    "#join elon and bored_elon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Date</th>\n",
       "      <th>Retweets</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RanNatanzon Tesla Cortica This is completely f...</td>\n",
       "      <td>Tue Mar 20 18:47:20 +0000 2018</td>\n",
       "      <td>195</td>\n",
       "      <td>BoredElon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Paid respects to Masada earlier today Live fre...</td>\n",
       "      <td>Tue Mar 20 02:20:29 +0000 2018</td>\n",
       "      <td>844</td>\n",
       "      <td>BoredElon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Learning how to pour flaming absinthe over a t...</td>\n",
       "      <td>Mon Mar 19 18:09:26 +0000 2018</td>\n",
       "      <td>970</td>\n",
       "      <td>BoredElon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IraEhrenpreis Tesla Thanks for your support ov...</td>\n",
       "      <td>Sun Mar 18 04:31:53 +0000 2018</td>\n",
       "      <td>157</td>\n",
       "      <td>BoredElon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TheOnion Your cruel taunts cut me deep Deep Bu...</td>\n",
       "      <td>Thu Mar 15 18:46:45 +0000 2018</td>\n",
       "      <td>465</td>\n",
       "      <td>BoredElon</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet  \\\n",
       "0  RanNatanzon Tesla Cortica This is completely f...   \n",
       "1  Paid respects to Masada earlier today Live fre...   \n",
       "2  Learning how to pour flaming absinthe over a t...   \n",
       "3  IraEhrenpreis Tesla Thanks for your support ov...   \n",
       "4  TheOnion Your cruel taunts cut me deep Deep Bu...   \n",
       "\n",
       "                             Date Retweets      Label  \n",
       "0  Tue Mar 20 18:47:20 +0000 2018      195  BoredElon  \n",
       "1  Tue Mar 20 02:20:29 +0000 2018      844  BoredElon  \n",
       "2  Mon Mar 19 18:09:26 +0000 2018      970  BoredElon  \n",
       "3  Sun Mar 18 04:31:53 +0000 2018      157  BoredElon  \n",
       "4  Thu Mar 15 18:46:45 +0000 2018      465  BoredElon  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bored_elon.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_tweets[“text”], all_tweets[“handle”], test_size=0.25, random_state=42, stratify=all_tweets[“handle”])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'map' object has no attribute 'lower'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-bb85cc3ab533>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mword_vectorizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCountVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mngram_range\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manalyzer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'word'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msparse_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword_vectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melon\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Tweet'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mfrequencies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msparse_matrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfrequencies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mword_vectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_feature_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'frequency'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m         vocabulary, X = self._count_vocab(raw_documents,\n\u001b[0;32m--> 869\u001b[0;31m                                           self.fixed_vocabulary_)\n\u001b[0m\u001b[1;32m    870\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[0;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[1;32m    790\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mraw_documents\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0mfeature_counter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 792\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0;32min\u001b[0m \u001b[0manalyze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    793\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    794\u001b[0m                     \u001b[0mfeature_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(doc)\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m             return lambda doc: self._word_ngrams(\n\u001b[0;32m--> 266\u001b[0;31m                 tokenize(preprocess(self.decode(doc))), stop_words)\n\u001b[0m\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlowercase\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstrip_accents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mstrip_accents\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'map' object has no attribute 'lower'"
     ]
    }
   ],
   "source": [
    "word_vectorizer = CountVectorizer(ngram_range=(1,2), analyzer='word')\n",
    "sparse_matrix = word_vectorizer.fit_transform(elon['Tweet'])\n",
    "frequencies = sum(sparse_matrix).toarray()[0]\n",
    "\n",
    "pd.DataFrame(frequencies, index=word_vectorizer.get_feature_names(), columns=['frequency'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Date</th>\n",
       "      <th>Retweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>All across this nation, we pray for our countr...</td>\n",
       "      <td>Wed Mar 14 00:34:44 +0000 2018</td>\n",
       "      <td>9018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>It was my great honor to deliver a message at ...</td>\n",
       "      <td>Wed Mar 14 00:25:59 +0000 2018</td>\n",
       "      <td>7481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>If we don’t have a wall system, we’re not goin...</td>\n",
       "      <td>Tue Mar 13 22:23:26 +0000 2018</td>\n",
       "      <td>15458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>California’s sanctuary policies are illegal an...</td>\n",
       "      <td>Tue Mar 13 15:27:18 +0000 2018</td>\n",
       "      <td>25657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>“According to the Center for Immigration Studi...</td>\n",
       "      <td>Tue Mar 13 15:24:23 +0000 2018</td>\n",
       "      <td>16217</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet  \\\n",
       "0  All across this nation, we pray for our countr...   \n",
       "1  It was my great honor to deliver a message at ...   \n",
       "2  If we don’t have a wall system, we’re not goin...   \n",
       "3  California’s sanctuary policies are illegal an...   \n",
       "4  “According to the Center for Immigration Studi...   \n",
       "\n",
       "                             Date Retweets  \n",
       "0  Wed Mar 14 00:34:44 +0000 2018     9018  \n",
       "1  Wed Mar 14 00:25:59 +0000 2018     7481  \n",
       "2  Tue Mar 13 22:23:26 +0000 2018    15458  \n",
       "3  Tue Mar 13 15:27:18 +0000 2018    25657  \n",
       "4  Tue Mar 13 15:24:23 +0000 2018    16217  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Date'] = pd.to_datetime(data['Date'], errors='coerce')\n",
    "data = data.dropna(subset=['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Date</th>\n",
       "      <th>Retweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3108</th>\n",
       "      <td>The Great State of Michigan was just certified...</td>\n",
       "      <td>2016-11-29 11:15:49</td>\n",
       "      <td>20554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3109</th>\n",
       "      <td>.@CNN is so embarrassed by their total  (100%)...</td>\n",
       "      <td>2016-11-29 03:03:59</td>\n",
       "      <td>23790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3112</th>\n",
       "      <td>@JoeBowman12: @jeffzeleny just another generic...</td>\n",
       "      <td>2016-11-29 02:15:54</td>\n",
       "      <td>7278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3113</th>\n",
       "      <td>@HighonHillcrest: @jeffzeleny what PROOF do u ...</td>\n",
       "      <td>2016-11-29 02:14:04</td>\n",
       "      <td>7508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3114</th>\n",
       "      <td>Just met with General Petraeus--was very impre...</td>\n",
       "      <td>2016-11-28 21:01:47</td>\n",
       "      <td>13176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3115</th>\n",
       "      <td>If Cuba is unwilling to make a better deal for...</td>\n",
       "      <td>2016-11-28 14:02:06</td>\n",
       "      <td>23395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3116</th>\n",
       "      <td>Serious voter fraud in Virginia, New Hampshire...</td>\n",
       "      <td>2016-11-28 00:31:54</td>\n",
       "      <td>29588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3117</th>\n",
       "      <td>states instead of the 15 states that I visited...</td>\n",
       "      <td>2016-11-27 20:41:32</td>\n",
       "      <td>10262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3118</th>\n",
       "      <td>It would have been much easier for me to win t...</td>\n",
       "      <td>2016-11-27 20:34:18</td>\n",
       "      <td>11000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3119</th>\n",
       "      <td>In addition to winning the Electoral College i...</td>\n",
       "      <td>2016-11-27 20:30:43</td>\n",
       "      <td>50642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3120</th>\n",
       "      <td>Trump is going to be our President. We owe him...</td>\n",
       "      <td>2016-11-27 13:29:30</td>\n",
       "      <td>16309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3121</th>\n",
       "      <td>during a general election. I, for one, am appa...</td>\n",
       "      <td>2016-11-27 13:08:05</td>\n",
       "      <td>8617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3122</th>\n",
       "      <td>and fair elections. We've accepted the outcome...</td>\n",
       "      <td>2016-11-27 13:01:08</td>\n",
       "      <td>9479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3123</th>\n",
       "      <td>Hillary's debate answer on delay: That is horr...</td>\n",
       "      <td>2016-11-27 12:55:03</td>\n",
       "      <td>10711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3124</th>\n",
       "      <td>Hillary Clinton conceded the election when she...</td>\n",
       "      <td>2016-11-27 12:19:31</td>\n",
       "      <td>25251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3125</th>\n",
       "      <td>The Democrats, when they incorrectly thought t...</td>\n",
       "      <td>2016-11-27 03:59:52</td>\n",
       "      <td>29685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3126</th>\n",
       "      <td>The Green Party scam to fill up their coffers ...</td>\n",
       "      <td>2016-11-27 00:31:32</td>\n",
       "      <td>30102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3127</th>\n",
       "      <td>Fidel Castro is dead!</td>\n",
       "      <td>2016-11-26 13:08:11</td>\n",
       "      <td>93670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3128</th>\n",
       "      <td>I am working hard, even on Thanksgiving, tryin...</td>\n",
       "      <td>2016-11-24 15:11:58</td>\n",
       "      <td>29302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3129</th>\n",
       "      <td>Happy Thanksgiving to everyone. We will, toget...</td>\n",
       "      <td>2016-11-24 03:30:36</td>\n",
       "      <td>46201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3130</th>\n",
       "      <td>Let us give thanks for all that we have, and l...</td>\n",
       "      <td>2016-11-24 02:17:26</td>\n",
       "      <td>46332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3131</th>\n",
       "      <td>Bus crash in Tennessee so sad &amp;amp; so terribl...</td>\n",
       "      <td>2016-11-23 00:24:46</td>\n",
       "      <td>26480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3132</th>\n",
       "      <td>I am seriously considering Dr. Ben Carson as t...</td>\n",
       "      <td>2016-11-22 17:10:47</td>\n",
       "      <td>25867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3133</th>\n",
       "      <td>The meeting with the @nytimes is back on at 12...</td>\n",
       "      <td>2016-11-22 15:40:31</td>\n",
       "      <td>6845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3134</th>\n",
       "      <td>'Jeff Sessions, a Fitting Selection for Attorn...</td>\n",
       "      <td>2016-11-22 13:39:46</td>\n",
       "      <td>10060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3135</th>\n",
       "      <td>'President-elect Donald J. Trump's CIA Directo...</td>\n",
       "      <td>2016-11-22 13:38:17</td>\n",
       "      <td>8260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3136</th>\n",
       "      <td>Great meetings will take place today at Trump ...</td>\n",
       "      <td>2016-11-22 11:46:57</td>\n",
       "      <td>16232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3137</th>\n",
       "      <td>The failing @nytimes just announced that compl...</td>\n",
       "      <td>2016-11-22 11:36:46</td>\n",
       "      <td>11313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3138</th>\n",
       "      <td>Perhaps a new meeting will be set up with the ...</td>\n",
       "      <td>2016-11-22 11:31:18</td>\n",
       "      <td>8970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3139</th>\n",
       "      <td>I cancelled today's meeting with the failing @...</td>\n",
       "      <td>2016-11-22 11:16:45</td>\n",
       "      <td>16465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3140</th>\n",
       "      <td>Many people would like to see @Nigel_Farage re...</td>\n",
       "      <td>2016-11-22 02:22:16</td>\n",
       "      <td>20880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3141</th>\n",
       "      <td>Prior to the election it was well known that I...</td>\n",
       "      <td>2016-11-22 02:14:21</td>\n",
       "      <td>18052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3142</th>\n",
       "      <td>.@transition2017 update and policy plans for t...</td>\n",
       "      <td>2016-11-21 23:58:06</td>\n",
       "      <td>39732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3143</th>\n",
       "      <td>I have always had a good relationship with Chu...</td>\n",
       "      <td>2016-11-20 14:05:01</td>\n",
       "      <td>11063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3144</th>\n",
       "      <td>General James Mad Dog\" Mattis who is being con...</td>\n",
       "      <td>2016-11-20 13:39:05</td>\n",
       "      <td>20678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3145</th>\n",
       "      <td>I watched parts of @nbcsnl Saturday Night Live...</td>\n",
       "      <td>2016-11-20 13:26:04</td>\n",
       "      <td>15212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3146</th>\n",
       "      <td>Numerous patriots will be coming to Bedminster...</td>\n",
       "      <td>2016-11-20 11:44:23</td>\n",
       "      <td>13358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3147</th>\n",
       "      <td>The cast and producers of Hamilton, which I he...</td>\n",
       "      <td>2016-11-20 11:22:34</td>\n",
       "      <td>24165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3148</th>\n",
       "      <td>The Theater must always be a safe and special ...</td>\n",
       "      <td>2016-11-19 13:56:30</td>\n",
       "      <td>41456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3149</th>\n",
       "      <td>Our wonderful future V.P. Mike Pence was haras...</td>\n",
       "      <td>2016-11-19 13:48:31</td>\n",
       "      <td>32145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3150</th>\n",
       "      <td>The ONLY bad thing about winning the Presidenc...</td>\n",
       "      <td>2016-11-19 13:39:34</td>\n",
       "      <td>12352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3151</th>\n",
       "      <td>I settled the Trump University lawsuit for a s...</td>\n",
       "      <td>2016-11-19 13:34:38</td>\n",
       "      <td>15487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3152</th>\n",
       "      <td>Will be working all weekend in choosing the gr...</td>\n",
       "      <td>2016-11-18 22:35:27</td>\n",
       "      <td>25303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3153</th>\n",
       "      <td>I worked hard with Bill Ford to keep the Linco...</td>\n",
       "      <td>2016-11-18 02:15:28</td>\n",
       "      <td>27932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3154</th>\n",
       "      <td>Just got a call from my friend Bill Ford, Chai...</td>\n",
       "      <td>2016-11-18 02:01:52</td>\n",
       "      <td>46812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3155</th>\n",
       "      <td>My transition team, which is working long hour...</td>\n",
       "      <td>2016-11-17 12:46:23</td>\n",
       "      <td>20236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3156</th>\n",
       "      <td>Australia, New Zealand, and more. I am always ...</td>\n",
       "      <td>2016-11-16 12:25:21</td>\n",
       "      <td>22789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3157</th>\n",
       "      <td>I have recieved and taken calls from many fore...</td>\n",
       "      <td>2016-11-16 12:17:12</td>\n",
       "      <td>24361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3158</th>\n",
       "      <td>The failing @nytimes story is so totally wrong...</td>\n",
       "      <td>2016-11-16 12:12:30</td>\n",
       "      <td>19736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3159</th>\n",
       "      <td>I am not trying to get top level security clea...</td>\n",
       "      <td>2016-11-16 11:28:57</td>\n",
       "      <td>31700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Tweet                Date  \\\n",
       "3108  The Great State of Michigan was just certified... 2016-11-29 11:15:49   \n",
       "3109  .@CNN is so embarrassed by their total  (100%)... 2016-11-29 03:03:59   \n",
       "3112  @JoeBowman12: @jeffzeleny just another generic... 2016-11-29 02:15:54   \n",
       "3113  @HighonHillcrest: @jeffzeleny what PROOF do u ... 2016-11-29 02:14:04   \n",
       "3114  Just met with General Petraeus--was very impre... 2016-11-28 21:01:47   \n",
       "3115  If Cuba is unwilling to make a better deal for... 2016-11-28 14:02:06   \n",
       "3116  Serious voter fraud in Virginia, New Hampshire... 2016-11-28 00:31:54   \n",
       "3117  states instead of the 15 states that I visited... 2016-11-27 20:41:32   \n",
       "3118  It would have been much easier for me to win t... 2016-11-27 20:34:18   \n",
       "3119  In addition to winning the Electoral College i... 2016-11-27 20:30:43   \n",
       "3120  Trump is going to be our President. We owe him... 2016-11-27 13:29:30   \n",
       "3121  during a general election. I, for one, am appa... 2016-11-27 13:08:05   \n",
       "3122  and fair elections. We've accepted the outcome... 2016-11-27 13:01:08   \n",
       "3123  Hillary's debate answer on delay: That is horr... 2016-11-27 12:55:03   \n",
       "3124  Hillary Clinton conceded the election when she... 2016-11-27 12:19:31   \n",
       "3125  The Democrats, when they incorrectly thought t... 2016-11-27 03:59:52   \n",
       "3126  The Green Party scam to fill up their coffers ... 2016-11-27 00:31:32   \n",
       "3127                              Fidel Castro is dead! 2016-11-26 13:08:11   \n",
       "3128  I am working hard, even on Thanksgiving, tryin... 2016-11-24 15:11:58   \n",
       "3129  Happy Thanksgiving to everyone. We will, toget... 2016-11-24 03:30:36   \n",
       "3130  Let us give thanks for all that we have, and l... 2016-11-24 02:17:26   \n",
       "3131  Bus crash in Tennessee so sad &amp; so terribl... 2016-11-23 00:24:46   \n",
       "3132  I am seriously considering Dr. Ben Carson as t... 2016-11-22 17:10:47   \n",
       "3133  The meeting with the @nytimes is back on at 12... 2016-11-22 15:40:31   \n",
       "3134  'Jeff Sessions, a Fitting Selection for Attorn... 2016-11-22 13:39:46   \n",
       "3135  'President-elect Donald J. Trump's CIA Directo... 2016-11-22 13:38:17   \n",
       "3136  Great meetings will take place today at Trump ... 2016-11-22 11:46:57   \n",
       "3137  The failing @nytimes just announced that compl... 2016-11-22 11:36:46   \n",
       "3138  Perhaps a new meeting will be set up with the ... 2016-11-22 11:31:18   \n",
       "3139  I cancelled today's meeting with the failing @... 2016-11-22 11:16:45   \n",
       "3140  Many people would like to see @Nigel_Farage re... 2016-11-22 02:22:16   \n",
       "3141  Prior to the election it was well known that I... 2016-11-22 02:14:21   \n",
       "3142  .@transition2017 update and policy plans for t... 2016-11-21 23:58:06   \n",
       "3143  I have always had a good relationship with Chu... 2016-11-20 14:05:01   \n",
       "3144  General James Mad Dog\" Mattis who is being con... 2016-11-20 13:39:05   \n",
       "3145  I watched parts of @nbcsnl Saturday Night Live... 2016-11-20 13:26:04   \n",
       "3146  Numerous patriots will be coming to Bedminster... 2016-11-20 11:44:23   \n",
       "3147  The cast and producers of Hamilton, which I he... 2016-11-20 11:22:34   \n",
       "3148  The Theater must always be a safe and special ... 2016-11-19 13:56:30   \n",
       "3149  Our wonderful future V.P. Mike Pence was haras... 2016-11-19 13:48:31   \n",
       "3150  The ONLY bad thing about winning the Presidenc... 2016-11-19 13:39:34   \n",
       "3151  I settled the Trump University lawsuit for a s... 2016-11-19 13:34:38   \n",
       "3152  Will be working all weekend in choosing the gr... 2016-11-18 22:35:27   \n",
       "3153  I worked hard with Bill Ford to keep the Linco... 2016-11-18 02:15:28   \n",
       "3154  Just got a call from my friend Bill Ford, Chai... 2016-11-18 02:01:52   \n",
       "3155  My transition team, which is working long hour... 2016-11-17 12:46:23   \n",
       "3156  Australia, New Zealand, and more. I am always ... 2016-11-16 12:25:21   \n",
       "3157  I have recieved and taken calls from many fore... 2016-11-16 12:17:12   \n",
       "3158  The failing @nytimes story is so totally wrong... 2016-11-16 12:12:30   \n",
       "3159  I am not trying to get top level security clea... 2016-11-16 11:28:57   \n",
       "\n",
       "     Retweets  \n",
       "3108    20554  \n",
       "3109    23790  \n",
       "3112     7278  \n",
       "3113     7508  \n",
       "3114    13176  \n",
       "3115    23395  \n",
       "3116    29588  \n",
       "3117    10262  \n",
       "3118    11000  \n",
       "3119    50642  \n",
       "3120    16309  \n",
       "3121     8617  \n",
       "3122     9479  \n",
       "3123    10711  \n",
       "3124    25251  \n",
       "3125    29685  \n",
       "3126    30102  \n",
       "3127    93670  \n",
       "3128    29302  \n",
       "3129    46201  \n",
       "3130    46332  \n",
       "3131    26480  \n",
       "3132    25867  \n",
       "3133     6845  \n",
       "3134    10060  \n",
       "3135     8260  \n",
       "3136    16232  \n",
       "3137    11313  \n",
       "3138     8970  \n",
       "3139    16465  \n",
       "3140    20880  \n",
       "3141    18052  \n",
       "3142    39732  \n",
       "3143    11063  \n",
       "3144    20678  \n",
       "3145    15212  \n",
       "3146    13358  \n",
       "3147    24165  \n",
       "3148    41456  \n",
       "3149    32145  \n",
       "3150    12352  \n",
       "3151    15487  \n",
       "3152    25303  \n",
       "3153    27932  \n",
       "3154    46812  \n",
       "3155    20236  \n",
       "3156    22789  \n",
       "3157    24361  \n",
       "3158    19736  \n",
       "3159    31700  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.to_csv('data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
